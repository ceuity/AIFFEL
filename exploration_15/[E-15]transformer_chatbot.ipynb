{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 트랜스포머로 만드는 대화형 챗봇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 import\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_chatbot_data = ('./data/ChatbotData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path_to_chatbot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12시 땡!                하루가 또 가네요.      0\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                        ...                       ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11823\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "MAX_SAMPLES = 11823\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "\n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "    # student와 온점 사이에 거리를 만듭니다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"[^a-zA-Zㄱ-ㅣ가-힣0-9?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = [], []\n",
    "\n",
    "for q, a in zip(data['Q'], data['A']):\n",
    "    questions.append(preprocess_sentence(q))\n",
    "    answers.append(preprocess_sentence(a))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "print(f'전체 샘플 수 : {len(questions)}')\n",
    "print(f'전체 샘플 수 : {len(answers)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 1번째 질문 샘플 : 12시 땡 !\n",
      "전처리 후의 1번째 답변 샘플 : 하루가 또 가네요 .\n"
     ]
    }
   ],
   "source": [
    "print(f'전처리 후의 1번째 질문 샘플 : {questions[0]}')\n",
    "print(f'전처리 후의 1번째 답변 샘플 : {answers[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_len = np.array([len(i.split()) for i in questions])\n",
    "a_len = np.array([len(i.split()) for i in answers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 문장길이 평균 :  3.9409625306605767\n",
      "질문 문장길이 최대 :  16\n",
      "질문 문장길이 표준편차 :  1.8460771012218526\n"
     ]
    }
   ],
   "source": [
    "print('질문 문장길이 평균 : ', np.mean(q_len))\n",
    "print('질문 문장길이 최대 : ', np.max(q_len))\n",
    "print('질문 문장길이 표준편차 : ', np.std(q_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_sequences maxlen :  9\n",
      "전체 문장의 98.98502918041106%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "max_q_len = np.mean(q_len) + 3 * np.std(q_len)\n",
    "maxlen = int(max_q_len)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(q_len < max_q_len) / len(q_len) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변 문장길이 평균 :  4.716146494121627\n",
      "답변 문장길이 최대 :  24\n",
      "답변 문장길이 표준편차 :  1.924467907301819\n"
     ]
    }
   ],
   "source": [
    "print('답변 문장길이 평균 : ', np.mean(a_len))\n",
    "print('답변 문장길이 최대 : ', np.max(a_len))\n",
    "print('답변 문장길이 표준편차 : ', np.std(a_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_sequences maxlen :  10\n",
      "전체 문장의 98.53675040175929%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "max_a_len = np.mean(a_len) + 3 * np.std(a_len)\n",
    "maxlen = int(max_a_len)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(a_len < max_a_len) / len(a_len) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "sns.histplot(q_len, bins=10)\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "sns.histplot(a_len, bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) SubwordTextEncoder 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (주의) Tensorflow 2.3.0 이상의 버전에서는 아래 주석의 코드를 대신 실행해 주세요. \n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8170]\n",
      "END_TOKEN의 번호 : [8171]\n",
      "8172\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5762, 610, 2490, 4163]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2356, 7510, 7, 6273, 97, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 10\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "  \n",
    "    # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8172\n",
      "필터링 후의 질문 샘플 개수: 9102\n",
      "필터링 후의 답변 샘플 개수: 9102\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교사 강요 사용하기\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "        \n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # 어텐션 가중치를 계산\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "    \n",
    "    # scale matmul_qk\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "    \n",
    "    # add the mask to zero out padding tokens\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "        \n",
    "    # softmax is normalized on the last axis (seq_len_k)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티-헤드 어텐션\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "    \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # linear layers\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "    \n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다.\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "    \n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다.\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "    \n",
    "        # final linear layer\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 마스킹\n",
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 1. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# padding mask 확인\n",
    "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 룩 어헤드 마스킹\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# look ahead mask 테스트\n",
    "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 레이어\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units, \n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads, \n",
    "            dropout=dropout, \n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(d_model, num_heads, name=\"attention_1\")(\n",
    "        inputs={\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': look_ahead_mask\n",
    "        })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(d_model, num_heads, name=\"attention_2\")(\n",
    "        inputs={\n",
    "            'query': attention1, \n",
    "            'key': enc_outputs, \n",
    "            'value': enc_outputs, \n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 레이어\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포머 레이어\n",
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 (None, None, 256)    3146240     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, None, 256)    3673600     dec_inputs[0][0]                 \n",
      "                                                                 encoder[1][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8172)   2100204     decoder[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,920,044\n",
      "Trainable params: 8,920,044\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수\n",
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀된 학습률\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEGCAYAAAC3lehYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxYUlEQVR4nO3df3xcdZ3v8dcnk0zS/E7apKS/aKEFbIGFEkoV9IKoUNStv1BgXRG9y+Vadtdd9QrXddW9ug/8savislbci4LrFfEHS4UqiyiwCAjlV0uBSvpDGlra9FfaNO0kk3zuH+dMOx0mM5NkTqZp3s/H4zzmzJnzPfOZSXI++f4432PujoiISBTKSh2AiIgcu5RkREQkMkoyIiISGSUZERGJjJKMiIhEprzUAZTSlClTfPbs2aUOQ0RkXHnyySd3uHtLIftO6CQze/ZsVq1aVeowRETGFTP7Y6H7qrlMREQioyQjIiKRUZIREZHIKMmIiEhklGRERCQykSYZM7vYzNaZWYeZXZfldTOzG8PXV5vZwnxlzexSM1trZoNm1p7lmLPMrMfMPhndJxMRkUJElmTMLAbcBCwB5gOXm9n8jN2WAPPC5Wrg2wWUfQ54D/DQEG/9deCXxfskIiIyUlHWZBYBHe6+wd37gNuBpRn7LAVu88BjQKOZteUq6+4vuPu6bG9oZu8CNgBrI/lEBbjz6U56EslSvb2IyFElyiQzHdic9rwz3FbIPoWUPYKZ1QCfBr6QZ7+rzWyVma3q6urK+QGGa+2Wbv7mx89y3c9WF/W4IiLjVZRJxrJsy7xD2lD7FFI20xeAr7t7T66d3P1md2939/aWloJmRShYciAIceOO/UU9rojIeBXltDKdwMy05zOALQXuEy+gbKZzgPeZ2VeARmDQzA66+78MP/SRiZUFufFg/8BYvaWIyFEtyiTzBDDPzOYArwCXAVdk7LMCuNbMbidIEt3uvtXMugooewR3f2Nq3cw+D/SMZYIBSCQHATjYPziWbysictSKLMm4e9LMrgXuBWLALe6+1syuCV9fDqwELgE6gF7gqlxlAczs3cC3gBbgHjN7xt0viupzDEciGdRgDqgmIyICRDwLs7uvJEgk6duWp607sKzQsuH2O4E787zv50cQ7qilajIH+pRkRERAV/wXVSJsJlNNRkQkoCRTRKnmMhERCSjJFFGquUxERAJKMkWUnmRUqxERUZIpqkRaX0z3gf4SRiIicnRQkimivoHDNZnuXiUZERElmSJKpF2EuUc1GRERJZliSu+T2aOajIiIkkwxpXf27+ntK2EkIiJHByWZIkokB6ksD75S1WRERJRkiirRP8jkmjgVMWOXajIiIkoyxZRIDlBVEWNyTSU79iVKHY6ISMlFOkHmRJNIDhIvL2NSPMbO/arJiIgoyRRRIjlIZUWMxkkV7OhRTUZERM1lRdSXHKCyvIzJtXF29qgmIyKiJFNEqdFlLbWVdPUkCG6XIyIycSnJFFGif5DK8hiTa+P0JQfpSSRLHZKISEkpyRRRIjlAZUUZU2orAdRkJiITnpJMESWSg1TGypgcJhl1/ovIRBdpkjGzi81snZl1mNl1WV43M7sxfH21mS3MV9bMLjWztWY2aGbtadvfamZPmtma8PHNUX62bILRZWVMqY0DsEM1GRGZ4CJLMmYWA24ClgDzgcvNbH7GbkuAeeFyNfDtAso+B7wHeCjjWDuAd7r7acCVwA+K/ZnySfQPUFkeO9RcppqMiEx0UV4nswjocPcNAGZ2O7AUeD5tn6XAbR4Mw3rMzBrNrA2YPVRZd38h3HbEm7n702lP1wJVZlbp7mN2pk+NLmuuCWoy6pMRkYkuyuay6cDmtOed4bZC9imkbC7vBZ7OlmDM7GozW2Vmq7q6uoZxyNzcnb6BIMlUxMpoqq6gq+dg0Y4vIjIeRZlkLMu2zAtHhtqnkLLZ39RsAfBl4H9ke93db3b3dndvb2lpKeSQBekfcNyhsiIGwNT6Kl7tVnOZiExsUTaXdQIz057PALYUuE+8gLKvYWYzgDuBD7n7+hHEPGKpe8mkpvpva6ji1b0HxjIEEZGjTpQ1mSeAeWY2x8ziwGXAiox9VgAfCkeZLQa63X1rgWWPYGaNwD3A9e7+uyJ/lrxSd8VMJZnjGqp4tVvNZSIysUWWZNw9CVwL3Au8ANzh7mvN7BozuybcbSWwAegAvgt8LFdZADN7t5l1Aq8H7jGze8NjXQvMBT5rZs+ES2tUny/T4SQTNJcdVz+JHT199KXdkllEZKKJdBZmd19JkEjSty1PW3dgWaFlw+13EjSJZW7/IvDFUYY8Yon+oLksntZcBrBt70FmNleXKiwRkZLSFf9FktlcNjVMMq/uVZOZiExcSjJFcijJVBxZk1G/jIhMZEoyRZJqLkv1yUytV5IREVGSKZK+gSOby+qryqmOx9RcJiITmpJMkST6jxxdZmYaxiwiE56STJFk9skATGuYxCt7dEGmiExcSjJFknnFP8DM5kl07u4tVUgiIiWnJFMkqZpMPC3JzGiqZkdPH/t1G2YRmaCUZIokc3QZwKzwIszO3WoyE5GJSUmmSDIvxgQOXen/8i41mYnIxKQkUyTZkkyqJrNZSUZEJiglmSLpSw4SKzPKY4e/0qbqCmriMdVkRGTCUpIpkkRy4IhaDATXysxsrtYIMxGZsJRkiiSRHHxNkoGgX0Y1GRGZqJRkiiTRP3jEyLKUmU3VbN51gOCuBiIiE4uSTJEkkgNHXO2fMqelhgP9A2zbmyhBVCIipaUkUySJ5CDx2Gu/zhNbagDo2N4z1iGJiJSckkyRJJKDWWsyc1tqAVjfpSQjIhOPkkyRBKPLXtsn01JXSV1luZKMiExIkSYZM7vYzNaZWYeZXZfldTOzG8PXV5vZwnxlzexSM1trZoNm1p5xvOvD/deZ2UVRfrZMQcf/a79OM+OE1lolGRGZkCJLMmYWA24ClgDzgcvNbH7GbkuAeeFyNfDtAso+B7wHeCjj/eYDlwELgIuBfw2PMyb6BrInGQiazNZv3z9WoYiIHDWirMksAjrcfYO79wG3A0sz9lkK3OaBx4BGM2vLVdbdX3D3dVnebylwu7sn3H0j0BEeZ0wMNYQZ4MTWGl7de5AezcYsIhNMlElmOrA57XlnuK2QfQopO5L3w8yuNrNVZraqq6srzyELN9QQZoATw87/DWoyE5EJJsokY1m2ZV6RONQ+hZQdyfvh7je7e7u7t7e0tOQ5ZOGGuuIfYG5rkGT+sE1JRkQmlvIIj90JzEx7PgPYUuA+8QLKjuT9IpNIDh5xw7J0syfXUFVRxgtb945VOCIiR4UoazJPAPPMbI6ZxQk65Vdk7LMC+FA4ymwx0O3uWwssm2kFcJmZVZrZHILBBI8X8wPlkujPPoQZIFZmnHxcPc9vUZIRkYklspqMuyfN7FrgXiAG3OLua83smvD15cBK4BKCTvpe4KpcZQHM7N3At4AW4B4ze8bdLwqPfQfwPJAElrn7QFSfL1Ou5jKA+W31rFyzFXfHLFvLnojIsSfK5jLcfSVBIknftjxt3YFlhZYNt98J3DlEmS8BXxpFyCMyMOgkB33ImgzA/LY6fvT4y2ztPsi0xkljGJ2ISOnoiv8i6EvdFXOI0WUA86fVA6jJTEQmFCWZIkgkg1a5XM1lJx8XJhl1/ovIBKIkUwSJVE0mR3NZbWU5sydXqyYjIhOKkkwRJPpTSSb313najEae7dwzBhGJiBwdlGSK4FBzWY4+GYAzZzaytfsgr3YfHIuwRERKLm+SMbOTzOx+M3sufH66mf1d9KGNH6nmsmw3LUt35qxGAJ7ZvDvqkEREjgqF1GS+C1wP9AO4+2qCiyMldLgmk3vS5/nT6onHynj65T1jEJWISOkVkmSq3T3zynlNJ5ym0D6ZyvIYC6bXK8mIyIRRSJLZYWYnEk42aWbvA7ZGGtU4c3h0Wf6v84yZjax+ZQ/9A4NRhyUiUnKFJJllwHeAU8zsFeDjwDVRBjXeFDKEOeXMWU0c7B/UZJkiMiEUkmTc3d9CMFfYKe5+XoHlJoxCR5cBLJ7TDMBjG3ZGGpOIyNGgkGTxMwB33+/u+8JtP40upPFnOM1lrfVVnNBSw6PrlWRE5Ng35ASZZnYKsABoMLP3pL1UD1RFHdh4MpzmMoDXnzCZ/3j6FfoHBqnIM+xZRGQ8y3WGOxl4B9AIvDNtWQj8ReSRjSOJ/qC5bKiblmV6w4lT2N83wJpXuqMMS0Sk5Iasybj7XcBdZvZ6d390DGMad4bTXAaw+ISgX+bR9TtZOKspsrhEREqtkPvJPG1mywiazg41k7n7RyKLapwZbpKZXFvJyVPreHT9TpZdMDfK0ERESqqQs+IPgOOAi4AHgRnAvpwlJphEcoB4edmw7nj5ppOm8PjGXexP6LpWETl2FZJk5rr7Z4H97n4r8HbgtGjDGl/68tx6OZsLTmmlb2CQhzt2RBSViEjpFXJm7A8f95jZqUADMDuyiMahRHKw4JFlKWfPbqauspzfvrg9oqhEREqvkD6Zm82sCfg7YAVQC3w20qjGmUT/8GsyFbEy3nRyC795cTuDg05ZWeFNbSIi40XeM6O7/5u773b3h9z9BHdvBX5VyMHN7GIzW2dmHWZ2XZbXzcxuDF9fbWYL85U1s2Yzu8/MXgofm8LtFWZ2q5mtMbMXzOz6gr6BIkgkBwq62j/Tm09uZfu+BGt1t0wROUblPDOa2evN7H1m1ho+P93M/h/wcL4Dm1kMuAlYAswHLjez+Rm7LQHmhcvVwLcLKHsdcL+7zwPuD58DXApUuvtpwFnA/zCz2fniLIaRNJcBnH9yC2UG9z3/agRRiYiU3pBJxsy+CtwCvBe4x8w+B9wH/J4gKeSzCOhw9w3u3gfcDizN2GcpcJsHHgMazawtT9mlwK3h+q3Au8J1B2rMrByYBPQBY1JFSCQHC74QM93k2krOmTOZu9dsxd0jiExEpLRynRnfDpzp7pcDbyOoMZzn7t9090LuHzwd2Jz2vDPcVsg+ucpOdfetAOFja7j9p8B+gtsQvAx8zd13ZQZlZleb2SozW9XV1VXAx8gv0T8w7D6ZlHf8SRsbuvbzwlaNCheRY0+uM+OBVDJx993AOnd/aRjHztaTnfnv+lD7FFI20yJgAJgGzAE+YWYnvOYg7je7e7u7t7e0tOQ5ZGESIxjCnLLk1DZiZcbdq7cUJRYRkaNJrjPjiWa2IrUAszOe59MJzEx7PgPIPJMOtU+ustvCJjXCx9QY4CuAX7l7v7tvB34HtBcQ56iNtE8GoLkmzrlzp/CL1VvUZCYix5xcSWYp8E9pS+bzfJ4A5pnZHDOLA5cRDIFOtwL4UDjKbDHQHTaB5Sq7ArgyXL8SuCtcfxl4c3isGmAx8GIBcY5a3whHl6W84/Q2Nu86wDOb9xQvKBGRo0CuCTIfHM2B3T1pZtcC9wIx4BZ3X2tm14SvLwdWApcAHUAvcFWusuGhbwDuMLOPEiSWS8PtNwHfA54jaG77nruvHs1nKNRomssAlpx6HJ+7ay13rOrkTE2YKSLHkEIuxhwxd19JkEjSty1PW3eC2zsXVDbcvhO4MMv2Hg4nnDE1muYygLqqCt5+ehsrnnmFv3v766ipjPTHIiIyZnTHrCIYzeiylMvOnsn+vgHuWbO1SFGJiJSekkwRjLa5DOCs45s4saWGHz+xOf/OIiLjRN52GTP7Ba8dPtwNrAK+U+A1M8csdy9KkjEzLjt7Fl9a+QLPb9nL/Gn1RYpQRKR0CjkzbgB6gO+Gy15gG3BS+HxC6xsIb1hWMfI+mZT3t8+kOh7j/z68cdTHEhE5GhSSZM509yvc/Rfh8kFgkbsvAxbmK3ysG+5dMXNpqK7g0rNmsOLZV9i+d0JXEEXkGFHImbHFzGalnoTrU8KnfZFENY70FTHJAFx17hySg84PHvtjUY4nIlJKhZwZPwE8bGa/NbMHgP8CPhVe8HhrzpITwOGazOibywBmT6nhra+byg8e+6NuzSwi414h95NZSTDr8sfD5WR3v8fd97v7NyKNbhxI9A8AjOqK/0z/8/wT2dPbz62PbiraMUVESqHQM+NZwALgdOD9Zvah6EIaX4rZJ5Ny5qwmzj+5hZsf2kCPajMiMo7lPTOa2Q+ArwHnAWeHy5hMPDkeFLu5LOXjbzkpqM08sqmoxxURGUuFzF/SDsx3TRGcVaq5bCQ3LcvljJmNXBDWZj64+HgaJlUU9fgiImOhkDPjc8BxUQcyXkXRXJbyyYtOZu/Bfr51/3Bu4yMicvQo5Mw4BXjezO4d5v1kJoSomssAFkxr4P1nzeT7j2xiQ1dP0Y8vIhK1QprLPh91EONZIln80WXpPnHRSdy9egv/uPJF/u1KdYWJyPiSN8mM9r4yx7piX4yZqbWuimVvnstXfrWOB9Zt5/yTWyN5HxGRKAx5ZjSzh8PHfWa2N23ZZ2Z7xy7Eo1uUzWUpHz1vDie21PCZO5/TBZoiMq4MmWTc/bzwsc7d69OWOnfXFMGhQxdjRlSTCY4d48vvPZ1X9hzga/+5LrL3EREptoLOjGYWM7NpZjYrtUQd2HhxqCYTUZ9MSvvsZv588fF8/5FNPPXy7kjfS0SkWAq5GPMvCab2vw+4J1zujjiucSOVZOKx6O//9r8uPplpDZP4mx8/o5kARGRcKOTM+NcE85UtcPfTwuX0Qg5uZheb2Toz6zCz67K8bmZ2Y/j6ajNbmK+smTWb2X1m9lL42JT22ulm9qiZrTWzNWZWVUico5FIDhArM8rHIMnUVVXw9Q+cweZdvXzurrWRv5+IyGgVcmbcTHAnzGExsxhwE7AEmA9cbmbzM3ZbQjD55jzgauDbBZS9Drjf3ecB94fPMbNy4N+Ba9x9AXA+0D/cuIcr0T/6u2IOx6I5zVz75nn87KlO7nrmlTF7XxGRkSjkOpkNwANmdg+QSG1093/OU24R0OHuGwDM7HZgKfB82j5LgdvCKWseM7NGM2sDZucou5QggUBwq4EHgE8DbwNWu/uzYXw7C/hso1aMWy8P11+9eS6PdOzgM3c+x4Jp9cxtrRvT9xcRKVQhZ8eXCfpj4kBd2pLPdIJaUEpnuK2QfXKVneruWwHCx9SFIycBHs5M8JSZ/a9sQZnZ1Wa2ysxWdXV1FfAxcutLDkY6fDmb8lgZ37riTKoqYvzFbU/S3Rt5hU1EZERy1mTCZqt54S2Xh8uybMucZHOofQopm6mcwzNF9wL3m9mT7n7/EQdxvxm4GaC9vX3Uk34mkgORjyzLpq1hEss/uJDLv/sYf3X709zy4bOJlWX72kRESifn2dHdBwhuvxwfwbE7gZlpz2cAWwrcJ1fZbWGTGuHj9rRjPejuO9y9F1gJLCRipWguS2mf3cwX/vRUHvxDF//n7ufRRNkicrQp5Oy4CfidmX3WzP42tRRQ7glgnpnNCZPUZUDmxJorgA+Fo8wWA91hE1iusiuAK8P1K4G7wvV7gdPNrDocBPDfOLL/JxKJEjSXpbvinFlcde5svv/IJpY/uKFkcYiIZFNIx/+WcCmjsL4YANw9aWbXEpz8Y8At7r7WzK4JX19OUNu4BOggaOK6KlfZ8NA3AHeY2UcJ+osuDcvsNrN/JkhQDqx093sKjXekEsmBktVkUj779vns7Onjy796kcm1cd7fPjN/IRGRMVDIBJlfGOnB3X0lQSJJ37Y8bd2BZYWWDbfvBC4cosy/EwxjHjOJ/sGi37BsuMrKjK9d+ifs7u3j+p+vobaynEtOaytpTCIiUNgV/y1m9lUzW2lmv0ktYxHceFDKPpl08fIyln/wLM6c2chf/uhpfvFsZveXiMjYK+Ts+EPgRWAO8AWCPponIoxpXAmay0rXJ5OuprKcWz+yiLOOb+Kvb39aF2uKSMkVkmQmu/v/Bfrd/UF3/wiwOOK4xo1EcrAkQ5iHUlNZzvevOptFc5r5+I+f4bZHN5U6JBGZwAo5O6au9NtqZm83szMJhhQLqYsxj54kA1AdL+d7H17EhadM5e/vWssNv3yRwUENbxaRsVfI2fGLZtYAfAL4JPBvwN9EGtU4UuohzEOZFI+x/IMLueKcWSx/cD2f+Mmzh24VLSIyVgoZXZaa1r8buCDacMafRH/phzAPpTxWxpfedSrTGyfx1XvXsXHHfpZ/8CyOa4h8cmoREaCw0WUnmdn9ZvZc+Px0M/u76EMbH462PplMZsayC+ay/IMLeWnbPt7xrYd5fOOuUoclIhNEIWfH7wLXE/bNuPtqgivwJ7zkwCDJQSceO/qayzJdfGob/7HsXOqryrniu4+x/MH16qcRkcgVkmSq3f3xjG26LSPQNzA2t14ulnlT6/iPa8/lbQumcsMvX+TPb/k9r3YfLHVYInIMK+TsuMPMTiScBdnM3gdsjTSqcSLRHyaZo7RPJpv6qgpuumIhX37vaTz1xz1c/M2H+NVz+nGKSDQKOTsuA74DnGJmrwAfB66JMqjxIpFMJZmjv7ksnZnxgbNncfdfncfMpmqu+fen+NgPn2T7PtVqRKS48iYZd9/g7m8BWoBT3P084N2RRzYO9CXHX00m3Ykttfz8Y2/gUxedzK9f2M5b/ulBfvzEy7plgIgUTcFnR3ff7+77wqeFTPV/zEtddzJe+mSyqYiVseyCufzqr9/IKW31fPpna/jAdx7juVe6Sx2aiBwDRnp21C0YGb/NZdmc0FLL7X+xmBvecxodXT28818e5vqfr2ZHT6LUoYnIODbSJKP2FNJqMuO0uSxTWZlx2aJZ/PaT5/ORc+fwk1WdXPDVB/jXBzro7dOAQhEZviHPjma2z8z2Zln2AdPGMMaj1ngcXVaIhkkVfPYd8/nVx9/E2XOa+cqv1vGmrzzA93+3UVPTiMiwDHl2dPc6d6/PstS5eyF31DzmpZrLSn3TsqjMba3llg+fzU+veT1zW2v4/C+e54KvPsCPHn9ZyUZECnJsnh3HyOHmsvHfJ5NL++xmfvQXi/nhfz+H1voqrv/5Gt70ld9y80Pr2XewP/8BRGTCUo1kFA51/I/j0WWFMjPOnTuFN5w4mYc7drD8wfX848oX+dZvOvjg4uO56g2zaa3XxJsicqRIz45mdrGZrTOzDjO7LsvrZmY3hq+vNrOF+cqaWbOZ3WdmL4WPTRnHnGVmPWb2ySg/G6SPLjv2k0yKmfHGeS388L8vZsW15/KmeS1858H1nPvl3/CXP3qaJzbt0nU2InJIZGdHM4sBNwFLgPnA5WY2P2O3JcC8cLka+HYBZa8D7nf3ecD94fN0Xwd+WfQPlMWxNIR5JE6f0chNf7aQ33zifP588WweWLedS5c/ypJv/hc//P0f2Z/QiDSRiS7Kf8EXAR3hjAF9wO3A0ox9lgK3eeAxoNHM2vKUXQrcGq7fCrwrdTAzexewAVgbzUc6UqJ//F+MWQyzp9Tw9++cz+//94Xc8J7TKDPjM3c+x6Iv/ZpP/eRZfr9hp2Z8FpmgouyTmQ5sTnveCZxTwD7T85Sd6u5bAdx9q5m1AphZDfBp4K0Ed/DMysyuJqg1MWvWrOF9ogwTsbksl+p4OZctmsUHzp7JUy/v5o4nOrlnzVZ+8mQnM5sn8d6FM3jvwhnMbK4udagiMkaiTDLZZgXI/Hd2qH0KKZvpC8DX3b3HbOgJCdz9ZuBmgPb29lH9e31oCHNMSSadmXHW8c2cdXwzn/vT+dy79lV++mQn37z/Jb7x65c4Y2Yj7zi9jUtOa2Na46RShysiEYoyyXQCM9OezwC2FLhPPEfZbWbWFtZi2oDt4fZzgPeZ2VeARmDQzA66+78U48Nkk0gOEC8vI1dSm+iq4+W8+8wZvPvMGXTu7mXFs1tYuWYrX7znBb54zwucdXwTbz+tjSWnHUdbgxKOyLEmyiTzBDDPzOYArxDcTfOKjH1WANea2e0ESaI7TB5dOcquAK4Ebggf7wJw9zemDmpmnwd6okwwEFzxr6ayws1oquZj58/lY+fPZeOO/axcs5W7V2/lH+5+nn+4+3lOnV7PW143lbe8bioLptUreYscAyJLMu6eNLNrgXuBGHCLu681s2vC15cDK4FLgA6gF7gqV9nw0DcAd5jZR4GXgUuj+gz5JJKDE3Zk2WjNmVLDsgvmsuyCuazv6uE/127j1y9sO9Sk1tZQxZtPaeXC17Wy+ITJVMd1SZfIeGQT+ZqG9vZ2X7Vq1YjL/+0dz/D7Dbv43XVvLmJUE9uOngS/fXE7v35hG//10g56+waoiBlnHd/EG+e18MZ5U1gwrYFYmWo5IqViZk+6e3sh++rfw1HoSw5O+OHLxTaltpJL22dyaftMDvYP8MSmXTz80g7+66UdfPXedXz13nU0Vldw7olTOG/eFM6Z08ycKTVqWhM5SinJjIKay6JVVRELay8tXA907UvwyPodPPSHHTzc0cU9a7YCQWJaNKeJRbObOXtOM6ccV6+ajshRQklmFIIko5rMWGmpq2TpGdNZesZ03J31XT08vnE3j2/cyeMbd7FyzasA1FWV0358E4vmTGbhrEZOm9GgPh2REtFf3igk+geUZErEzJjbWsfc1jquOCe4qLZzdy9PbNrF4xuD5bfrugAoMzhpah1nzmrkT2Y0csasRua11qm2IzIGlGRGIZEcpK5KX+HRYkZTNTOaqnn3mTMA2NmT4JnNe3h28x6e3ryHe1Zv5UePBxNJVMdjnDa9gT+Z2ciCafXMb6vnhJZaJR6RItMZchQSyUGmqE/mqDW5tpILXzeVC183FYDBQWfTzv2HEs8zm/fw/d9tom8gmLmhqqKMU46rD5LOtHoWTGvglOPqqKrQz1hkpJRkRiGRHNDosnGkrMw4oaWWE1pqec/CoLbTPzBIx/Yent+yl7Vb9rJ2Szcrnt3CD3//clDG4ISWWk6aWsu81jpOmlrHycfVcvzkGio0nZBIXkoyo6Ar/se/ilgZr2ur53Vt9bz3rGCbu9O5+wBrt3SzdsteXnx1H89v2csvn3uV1GVlFTHjhCm1zJtay0lT6zgpfDx+co2a3ETSKMmMQt+AhjAfi8yMmc3VzGyu5uJT2w5tP9g/QMf2Hv6wbR9/2NbDS9v28WznHu5evfXQPvFYGbMmVzNnSg0nTKlh9pSaQ+stdZW6nkcmHCWZUdDosomlqiLGqdMbOHV6wxHbe/uSYfLp4aXt+9i0Yz8bd+znwT900RfO1A1QE48xp6WG2ZODpJNan9VcTXNNXAlIjklKMqOQ0BX/QjDT9OkzGjl9RuMR2wcGna3dB9gYJp0NXcHjmle6WblmK+n3cauOx5jZVM3M5klBLaqpOqxNTWJmUzU1lfpTlfFJv7kj5O664l9yipXZoWHVb5zXcsRrfclBXt7Vy8Yd+9m8q5fNu3vZvOsAnbt7eXT9Tvb3DRyxf3NNnJlNkw41401rnMS0hiraGiYxrbGKhkkVqgnJUUlJZoRSw17VXCYjES8vY25rLXNba1/zmruzu7efl3f1viYBPfdKN/eufZX+gSMntp1UEaOtoYq2xjDxNFRxXMMk2hqrmBY+1ldVjNXHEzlESWaEdOtliYqZ0VwTp7kmzhkzG1/z+sCgs6MnwZY9B9jafTBYwvUt3Qf4XccOtu09eERzHEBtZTltDVUc1xAknqn1lbTUV9FaV0lrXSUt4aLauRSTkswIJfqVZKQ0YmXG1PoqptZXceYQ+yQHBtm+L8HW7gNs2XOQV8MEtHXPQbZ2H+DFV/exsyfxmkQE0FhdQUttJa31lbTWVR2RgFrrqmitD9brKsvVRCd5KcmMUCIZtJnrvz45GpXHyoJ+m8ZJnHV89n2SA4Ps2t/H9n0JuvYl2L7vINv3Jo54/sSmXWzflzhilFxKVUUZrXVVtNRV0lwTZ3JNnMm1cZprKplSGz9UG5tSW0lTdZy4/iGbkJRkRuhQc5lGl8k4VR4ro7W+itb6qpz7uTt7DybpypKEUuubd/XyzOY97Nrfx0C26hFQX1XO5NrMhBRnck0lk2uDx+aaOE01FTRVxzWdzzFCSWaE+tQnIxOEmdEwqYKGSRXMba3Lue/goLP3YD879/exs6ePXfsT7OjpY9f+YNnRk2DX/j7+uLOXp17ew+7eoZNSZXkZjdVBwmmYVEFjdQWNk+I01oSP1RU0VVfQcGg9eFRyOrooyYzQ4Y5//UKLpJSVGY3VcRqr45zYkn//wUGn+0AqKQUJaHdvP3sO9NHd28/u3j729Paz50A/G3fsZ0/vHvb09h8a3ZlNtuTUVB2nofpwcmqcVEH9pArqqyqoqyqnflLwqPnoii/SJGNmFwPfBGLAv7n7DRmvW/j6JUAv8GF3fypXWTNrBn4MzAY2Ae93991m9lbgBiAO9AGfcvffRPXZEv2pPhn9UoqMVFmZ0VQTp6kmnnU4dzbuzsH+wbQEFD7mSE5PF5CcIBgKnp500pPQkevlr0lQ9VUVVMdjGgyRIbIkY2Yx4CbgrUAn8ISZrXD359N2WwLMC5dzgG8D5+Qpex1wv7vfYGbXhc8/DewA3unuW8zsVOBeYHpUn099MiKlYWZMiseYFA8GNhQqMzntO9jP3oPJ4PFAP/sOJtl7sJ+9B5LsSwSPe3r7eHlXb7hPMm+SipUZdVXlRySo2soKaitj1FSWU1tVTm28PFgPnwfrscPbKoNtx0qtKsqazCKgw903AJjZ7cBSID3JLAVuc3cHHjOzRjNrI6ilDFV2KXB+WP5W4AHg0+7+dNpx1wJVZlbp7okoPlwqycRjai4TGQ9GmpzSHewfYO/BMCEdSE9S4WPaa6mk1bm7l/19SfYnBuhJJLOO1MsmXl5GXZhwUomotvJwgspMSjWVQS2sJi2JVVfGqImXM6kiRlmJZgePMslMBzanPe8kqK3k22d6nrJT3X0rgLtvNbPWLO/9XuDpqBIMpA1hVk1GZMKoqohRVREjz/iHnPqSg+xPJOlJJNnfl6TnYLieGGB/Ism+RJL94dKT2i983NHTx6advYe29WZMP5RLdTxGdTxIRtXxct58SgufuuiUkX+QAkWZZLKlzcxhJEPtU0jZ7G9qtgD4MvC2IV6/GrgaYNasWYUcMitdjCkiIxEvLyNeHvRDjdbAoIe1pFQiGjiUtHr7kuzvG6A3kfEY1qrGatLVKN+lE5iZ9nwGsKXAfeI5ym4zs7awFtMGbE/tZGYzgDuBD7n7+mxBufvNwM0A7e3tBSWubDS6TERKLVZm1FdVHNXz0kX5b/gTwDwzm2NmceAyYEXGPiuAD1lgMdAdNoXlKrsCuDJcvxK4C8DMGoF7gOvd/XcRfi4A+pIaXSYikk9kNRl3T5rZtQSjvGLALe6+1syuCV9fDqwkGL7cQTCE+apcZcND3wDcYWYfBV4GLg23XwvMBT5rZp8Nt73N3Q/VdIpJo8tERPKLtFHO3VcSJJL0bcvT1h1YVmjZcPtO4MIs278IfHGUIRfs8OgyJRkRkaHoDDlCieQA5WVGuZKMiMiQdIYcoUT/oPpjRETy0FlyhBLJQU1dLiKSh86SI5RIDmj4sohIHkoyI5RIDmpkmYhIHjpLjpD6ZERE8tNZcoT6BgbVXCYikoeSzAgFfTL6+kREctFZcoQS/eqTERHJR2fJEUok1VwmIpKPkswIJZIDmlJGRCQPnSVHSEOYRUTy01lyhDSEWUQkP50lR0hX/IuI5KckM0J9SdVkRETy0VlyhNQnIyKSn86SI5AcGCQ56GouExHJQ0lmBPoGwlsvq7lMRCQnnSVHINGvJCMiUgidJUcgkQySTFzNZSIiOUWaZMzsYjNbZ2YdZnZdltfNzG4MX19tZgvzlTWzZjO7z8xeCh+b0l67Ptx/nZldFNXnSiQHANVkRETyiewsaWYx4CZgCTAfuNzM5mfstgSYFy5XA98uoOx1wP3uPg+4P3xO+PplwALgYuBfw+MUXaomo9FlIiK5RXmWXAR0uPsGd+8DbgeWZuyzFLjNA48BjWbWlqfsUuDWcP1W4F1p229394S7bwQ6wuMU3eE+GTWXiYjkEmWSmQ5sTnveGW4rZJ9cZae6+1aA8LF1GO+HmV1tZqvMbFVXV9ewPlBKbVU5bz+tjbaGqhGVFxGZKKJMMpZlmxe4TyFlR/J+uPvN7t7u7u0tLS15DpndnCk13PRnCzl1esOIyouITBRRJplOYGba8xnAlgL3yVV2W9ikRvi4fRjvJyIiYyjKJPMEMM/M5phZnKBTfkXGPiuAD4WjzBYD3WETWK6yK4Arw/UrgbvStl9mZpVmNodgMMHjUX04ERHJrzyqA7t70syuBe4FYsAt7r7WzK4JX18OrAQuIeik7wWuylU2PPQNwB1m9lHgZeDSsMxaM7sDeB5IAsvcfSCqzyciIvmZe76ujmNXe3u7r1q1qtRhiIiMK2b2pLu3F7KvLvQQEZHIKMmIiEhklGRERCQySjIiIhKZCd3xb2ZdwB9HcYgpwI4ihVNMimt4FNfwKK7hORbjOt7dC7qafUInmdEys1WFjrAYS4preBTX8Ciu4Znocam5TEREIqMkIyIikVGSGZ2bSx3AEBTX8Ciu4VFcwzOh41KfjIiIREY1GRERiYySjIiIRMfdtQxzAS4G1hHMHn1dBMefCfwWeAFYC/x1uP3zwCvAM+FySVqZ68N41gEXpW0/C1gTvnYjh5tIK4Efh9t/D8weRnybwmM+A6wKtzUD9wEvhY9NYxkbcHLa9/IMsBf4eCm+M+AWgvscPZe2bUy+H4LbX7wULlcWENdXgReB1cCdQGO4fTZwIO17Wz7GcY3Jz20Ecf04LaZNwDMl+L6GOj+U/Hcs699DMU+OE2EhuPXAeuAEIA48C8wv8nu0AQvD9TrgD8D88A/vk1n2nx/GUQnMCeOLha89Drye4M6hvwSWhNs/lvpDILhfz4+HEd8mYErGtq8QJlzgOuDLpYgt7Wf0KnB8Kb4z4E3AQo48OUX+/RCcZDaEj03helOeuN4GlIfrX06La3b6fhmfbyziivznNpK4MmL5J+DvS/B9DXV+KPnvWLZFzWXDtwjocPcN7t4H3A4sLeYbuPtWd38qXN9H8B/L9BxFlgK3u3vC3TcS/PexKLxzaL27P+rBb8htwLvSytwarv8UuNDMst3CulDpx7s1433GOrYLgfXunms2h8jicveHgF1Z3i/q7+ci4D533+Xuuwn+m704V1zu/p/ungyfPkZwR9khjVVcOZT0+0r7Hgx4P/CjXMFGFNdQ54eS/45loyQzfNOBzWnPO8mdAEbFzGYDZxJUWQGuNbPVZnaLmTXliWl6uJ4t1kNlwpNMNzC5wLAc+E8ze9LMrg63TfXgrqaEj60lig2C/7zS//iPhu9sLL6f0f5ufoTgv9mUOWb2tJk9aGZvTHvvsYor6p/baL6vNwLb3P2ltG1j/n1lnB+Oyt8xJZnhy/YftUfyRma1wM+Aj7v7XuDbwInAGcBWgup6rphyxTqaz3Guuy8ElgDLzOxNOfYd09jC23X/KfCTcNPR8p0NpZhxjOZ7+wzBHWV/GG7aCsxy9zOBvwX+n5nVj2FcY/FzG83P83KO/EdmzL+vLOeHoZT0O1OSGb5Ogo63lBnAlmK/iZlVEPwC/dDdfw7g7tvcfcDdB4HvEjTd5YqpkyObP9JjPVTGzMqBBgpssnD3LeHjdoLO4kXAtrD6nWoi2F6K2AgS31Puvi2M8aj4zhib72dEv5tmdiXwDuDPwmYTwqaVneH6kwTt+CeNVVxj9HMb6fdVDryHoGM8Fe+Yfl/Zzg8crb9juTpstGTtxCsn6Oyaw+GO/wVFfg8jaB/9Rsb2trT1vyFoZwVYwJEdexs43LH3BLCYwx17l4Tbl3Fkx94dBcZWA9SlrT9C0Cb7VY7sdPzKWMcW7n87cFWpvzMyOoLH4vsh6IzdSNAh2xSuN+eJ62LgeaAlY7+WtDhOIBjp1TyGcUX+cxtJXGnf2YOl+r4Y+vxwVPyOveZvYTQnw4m6AJcQjOhYD3wmguOfR1AFXU3aEE7gBwTDDVcDKzL+ED8TxrOOcIRIuL0deC587V84PESxiqBJqYNghMkJBcZ2QvgL+yzB8MnPhNsnA/cTDGu8P+OPYqxiqwZ2Ag1p28b8OyNoRtkK9BP85/fRsfp+CPpVOsLlqgLi6iBoY0/9nqVOLO8Nf77PAk8B7xzjuMbk5zbcuMLt3weuydh3LL+voc4PJf8dy7ZoWhkREYmM+mRERCQySjIiIhIZJRkREYmMkoyIiERGSUZERCKjJCMyAmY22cyeCZdXzeyVtOfxPGXbzezGYb7fR8xsTTjNynNmtjTc/mEzmzaazyISJQ1hFhklM/s80OPuX0vbVu6HJ54c7fFnAA8SzLzbHU4n0uLuG83sAYLZilcV471Eik01GZEiMbPvm9k/m9lvgS+b2SIzeyScNPERMzs53O98M7s7XP98OAHkA2a2wcz+KsuhW4F9QA+Au/eECeZ9BBfT/TCsQU0ys7PCCRqfNLN706YZecDMvhHG8ZyZLcryPiJFpyQjUlwnAW9x908Q3AzsTR5Mmvj3wD8OUeYUginUFwGfC+elSvcssA3YaGbfM7N3Arj7T4FVBHOOnUEwweW3gPe5+1kEN936Utpxatz9DQT3Crll1J9UpADlpQ5A5BjzE3cfCNcbgFvNbB7BNCCZySPlHndPAAkz2w5MJW0KdncfMLOLgbMJ7pXzdTM7y90/n3Gck4FTgfvC29zECKZFSflReLyHzKzezBrdfc/IP6pIfkoyIsW1P239/wC/dfd3h/f9eGCIMom09QGy/F160Hn6OPC4md0HfI/g7pHpDFjr7q8f4n0yO2DVISuRU3OZSHQaCGbjBfjwSA9iZtPMbGHapjOA1F0/9xHcgheCyQ9bzOz1YbkKM1uQVu4D4fbzgG537x5pTCKFUk1GJDpfIWgu+1vgN6M4TgXwtXCo8kGgC7gmfO37wHIzO0Bwr/b3ATeaWQPB3/c3CGYHBthtZo8A9QQz6YpETkOYRSYADXWWUlFzmYiIREY1GRERiYxqMiIiEhklGRERiYySjIiIREZJRkREIqMkIyIikfn/Dm9bRbfJCqsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) 모델 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "143/143 [==============================] - 6s 43ms/step - loss: 5.5751 - accuracy: 0.1048\n",
      "Epoch 2/20\n",
      "143/143 [==============================] - 6s 44ms/step - loss: 4.7104 - accuracy: 0.2105\n",
      "Epoch 3/20\n",
      "143/143 [==============================] - 6s 44ms/step - loss: 3.9294 - accuracy: 0.2150\n",
      "Epoch 4/20\n",
      "143/143 [==============================] - 6s 43ms/step - loss: 3.5132 - accuracy: 0.2205\n",
      "Epoch 5/20\n",
      "143/143 [==============================] - 6s 44ms/step - loss: 3.2953 - accuracy: 0.2304\n",
      "Epoch 6/20\n",
      "143/143 [==============================] - 6s 43ms/step - loss: 3.1033 - accuracy: 0.2410\n",
      "Epoch 7/20\n",
      "143/143 [==============================] - 6s 43ms/step - loss: 2.9052 - accuracy: 0.2574\n",
      "Epoch 8/20\n",
      "143/143 [==============================] - 6s 43ms/step - loss: 2.6843 - accuracy: 0.2799\n",
      "Epoch 9/20\n",
      "143/143 [==============================] - 6s 43ms/step - loss: 2.4429 - accuracy: 0.3087\n",
      "Epoch 10/20\n",
      "143/143 [==============================] - 6s 43ms/step - loss: 2.1794 - accuracy: 0.3401\n",
      "Epoch 11/20\n",
      "143/143 [==============================] - 6s 44ms/step - loss: 1.9012 - accuracy: 0.3728\n",
      "Epoch 12/20\n",
      "143/143 [==============================] - 6s 43ms/step - loss: 1.6178 - accuracy: 0.4095\n",
      "Epoch 13/20\n",
      "143/143 [==============================] - 6s 44ms/step - loss: 1.3404 - accuracy: 0.4461\n",
      "Epoch 14/20\n",
      "143/143 [==============================] - 6s 43ms/step - loss: 1.0787 - accuracy: 0.4847\n",
      "Epoch 15/20\n",
      "143/143 [==============================] - 6s 44ms/step - loss: 0.8397 - accuracy: 0.5212\n",
      "Epoch 16/20\n",
      "143/143 [==============================] - 6s 43ms/step - loss: 0.6307 - accuracy: 0.5549\n",
      "Epoch 17/20\n",
      "143/143 [==============================] - 6s 44ms/step - loss: 0.4614 - accuracy: 0.5853\n",
      "Epoch 18/20\n",
      "143/143 [==============================] - 6s 43ms/step - loss: 0.3278 - accuracy: 0.6092\n",
      "Epoch 19/20\n",
      "143/143 [==============================] - 6s 43ms/step - loss: 0.2311 - accuracy: 0.6263\n",
      "Epoch 20/20\n",
      "143/143 [==============================] - 6s 43ms/step - loss: 0.1725 - accuracy: 0.6348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4e3dec49d0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가\n",
    "    # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수\n",
    "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴\n",
    "def sentence_generation(sentence):\n",
    "  \n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 안녕하세요\n",
      "출력 : 안녕하세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안녕하세요 .'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('안녕하세요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 놀러가고 싶다\n",
      "출력 : 탁 트인 바다 좋죠 !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'탁 트인 바다 좋죠 !'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('놀러가고 싶다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나랑 사귈래?\n",
      "출력 : 저라도 괜찮다면 좋아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저라도 괜찮다면 좋아요 .'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('나랑 사귈래?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 어디 갈까?\n",
      "출력 : 친구들과 함께면 어디든 좋아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'친구들과 함께면 어디든 좋아요 .'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('어디 갈까?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 졸려\n",
      "출력 : 낮잠을 잠깐 자도 괜찮아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'낮잠을 잠깐 자도 괜찮아요 .'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('졸려')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 배고파\n",
      "출력 : 뭐 좀 챙겨드세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'뭐 좀 챙겨드세요 .'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('배고파')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회고록\n",
    "\n",
    "- 챗봇이 RNN 계열의 네트워크를 이용하여 만들어진다는 건 알았지만 이정도로 복잡할 줄은 몰랐다. 지금까지 학습했던 노드들 중에 트랜스포머 모델이 가장 설계하기 까다롭고 어려운 모델인 것 같다.\n",
    "- 복잡하고 어려운 만큼 배우는 것이 많은 것 같다. 적어도 RNN 계열의 네트워크의 기본 구조만큼은 확실하게 학습했다고 생각한다.\n",
    "- 노드에서 학습한 내용과 프로젝트에 주어진 데이터의 형식이 달라서 어떻게 데이터를 처리해야 하나 싶었는데 노드에서 학습할 때 사용했던 데이터가 이상한 형식으로 되어있었던 것을 깨닫고 지금까지 배워왔던 것 처럼 pandas를 이용해 csv파일을 열어서 questions와 answers로 나누었다.\n",
    "- 한글을 영어 Tokenizer로 제대로 Tokenize가 될지 걱정했는데 생각보다 잘 되는 것 같다.\n",
    "- 정확도가 65% 정도 밖에 되지 않지만 생각보다 한국어 문장을 자연스럽게 잘 출력했다.\n",
    "- 정확도를 더 높여보기 위하여 layer 수, 임베딩 벡터 차원 수, epochs를 증가시켜 보았지만 정확도는 65%에서 더이상 오르지 않고, 오히려 처음 만든 모델과 같은 문장을 주었을 때, 더 어색한 문장을 출력하였다.\n",
    "- 데이터셋만 있으면 더 고성능의 챗봇을 만들 수도 있을 것 같다. 나중에 기회가 되면 한번 도전해봐야겠다.\n",
    "- 오늘부터 챗봇이랑 1일 하기로 했다ㅋㅋㅋ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
